{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataextractor as de\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7033\n15\n"
     ]
    }
   ],
   "source": [
    "extr = de.DataExtractor()\n",
    "data = extr.load_json().to_array()\n",
    "\n",
    "print(len(data))\n",
    "print(len(data[0]))\n",
    "\n",
    "\n",
    "\n",
    "# Acousticiness [0]\n",
    "# Dancibility [1]\n",
    "# Duration [2]\n",
    "# Energy [3]\n",
    "# Explicit [4]\n",
    "# Instrumentalness [5]\n",
    "# Key [6]\n",
    "# Liveness [7]\n",
    "# Loudness [8]\n",
    "# Mode [9]\n",
    "# Speechiness [10]\n",
    "# Tempo [11]\n",
    "# Time signature [12]\n",
    "# Valence [13]\\\n",
    "# Pop [14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 3.35000e-06  4.55000e-01  2.31826e+05  9.63000e-01  0.00000e+00\n",
      "  1.51000e-02  0.00000e+00  3.14000e-01 -3.08400e+00  1.00000e+00\n",
      "  3.43000e-02  1.44996e+02  4.00000e+00  7.88000e-01  0.00000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n",
    "labels = data[:,-1]\n",
    "data = data[:,:-1]\n",
    "data = extr.normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Splitting values at 55.0\n",
      "0.7367822626492325\n"
     ]
    }
   ],
   "source": [
    "new_labels = extr.catagorize(labels, .75)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, new_labels, stratify=new_labels, random_state=1)\n",
    "\n",
    "clf = MLPClassifier(nesterovs_momentum=True, random_state=1, max_iter=500).fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4923\n2110\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, random_state=1, test_size=.3)\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.047148569355590086\n"
     ]
    }
   ],
   "source": [
    "#First MLP!!!\n",
    "clf = MLPRegressor().fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.05121036936778278\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels,\n",
    "                                                    random_state=1)\n",
    "regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Indexis: [] Test index: 0 Acc: 0.001084746478716592\n",
      "Indexis: [] Test index: 1 Acc: 0.0010392673532420016\n",
      "Indexis: [] Test index: 2 Acc: 0.00054984925485424\n",
      "Indexis: [] Test index: 3 Acc: 0.0008463767808530864\n",
      "Indexis: [] Test index: 4 Acc: 0.03486347120366151\n",
      "Indexis: [] Test index: 5 Acc: 0.012034501391231078\n",
      "Indexis: [] Test index: 6 Acc: -2.8670607325143038e-05\n",
      "Indexis: [] Test index: 7 Acc: 9.357062897286106e-05\n",
      "Indexis: [] Test index: 8 Acc: 0.0014067604490776153\n",
      "Indexis: [] Test index: 9 Acc: 0.0019209344952062501\n",
      "Indexis: [] Test index: 10 Acc: 0.015705109147233665\n",
      "Indexis: [] Test index: 11 Acc: 3.599603615311864e-05\n",
      "Indexis: [] Test index: 12 Acc: -0.002493036299032969\n",
      "Indexis: [] Test index: 13 Acc: 0.0019811136532422724\n",
      "Indexis: [4] Test index: 0 Acc: 0.03627622123461283\n",
      "Indexis: [4] Test index: 1 Acc: 0.03388823236980054\n",
      "Indexis: [4] Test index: 2 Acc: 0.03529940829254663\n",
      "Indexis: [4] Test index: 3 Acc: 0.03518266906351886\n",
      "Indexis: [4] Test index: 5 Acc: 0.0426773077528555\n",
      "Indexis: [4] Test index: 6 Acc: 0.03478503444441228\n",
      "Indexis: [4] Test index: 7 Acc: 0.03548261213832227\n",
      "Indexis: [4] Test index: 8 Acc: 0.03538266989657213\n",
      "Indexis: [4] Test index: 9 Acc: 0.034624715881509394\n",
      "Indexis: [4] Test index: 10 Acc: 0.03722477535077984\n",
      "Indexis: [4] Test index: 11 Acc: 0.03468527905096974\n",
      "Indexis: [4] Test index: 12 Acc: 0.032502186748606166\n",
      "Indexis: [4] Test index: 13 Acc: 0.03918080632523291\n",
      "Indexis: [4, 5] Test index: 0 Acc: 0.04538980889368227\n",
      "Indexis: [4, 5] Test index: 1 Acc: 0.042293125248057506\n",
      "Indexis: [4, 5] Test index: 2 Acc: 0.04294025239730026\n",
      "Indexis: [4, 5] Test index: 3 Acc: 0.04521110056320321\n",
      "Indexis: [4, 5] Test index: 6 Acc: 0.04259436251460558\n",
      "Indexis: [4, 5] Test index: 7 Acc: 0.043681086784069456\n",
      "Indexis: [4, 5] Test index: 8 Acc: 0.04160288504388221\n",
      "Indexis: [4, 5] Test index: 9 Acc: 0.04312045398641784\n",
      "Indexis: [4, 5] Test index: 10 Acc: 0.04483089611427982\n",
      "Indexis: [4, 5] Test index: 11 Acc: 0.042576125435237144\n",
      "Indexis: [4, 5] Test index: 12 Acc: 0.04134998441364812\n",
      "Indexis: [4, 5] Test index: 13 Acc: 0.04837694468647724\n",
      "Indexis: [4, 5, 13] Test index: 0 Acc: 0.049588703178694016\n",
      "Indexis: [4, 5, 13] Test index: 1 Acc: 0.04796964376275825\n",
      "Indexis: [4, 5, 13] Test index: 2 Acc: 0.04894636282671205\n",
      "Indexis: [4, 5, 13] Test index: 3 Acc: 0.04872621130491506\n",
      "Indexis: [4, 5, 13] Test index: 6 Acc: 0.04769111294446571\n",
      "Indexis: [4, 5, 13] Test index: 7 Acc: 0.049739363156643956\n",
      "Indexis: [4, 5, 13] Test index: 8 Acc: 0.04844745795248118\n",
      "Indexis: [4, 5, 13] Test index: 9 Acc: 0.04838924751174245\n",
      "Indexis: [4, 5, 13] Test index: 10 Acc: 0.051481306855109654\n",
      "Indexis: [4, 5, 13] Test index: 11 Acc: 0.047680018112342015\n",
      "Indexis: [4, 5, 13] Test index: 12 Acc: 0.046119408894894964\n",
      "Indexis: [4, 5, 13, 10] Test index: 0 Acc: 0.05275574822497808\n",
      "Indexis: [4, 5, 13, 10] Test index: 1 Acc: 0.051311861990531504\n",
      "Indexis: [4, 5, 13, 10] Test index: 2 Acc: 0.05202949261772982\n",
      "Indexis: [4, 5, 13, 10] Test index: 3 Acc: 0.052588755767172146\n",
      "Indexis: [4, 5, 13, 10] Test index: 6 Acc: 0.05082407798034427\n",
      "Indexis: [4, 5, 13, 10] Test index: 7 Acc: 0.05335557125051971\n",
      "Indexis: [4, 5, 13, 10] Test index: 8 Acc: 0.05190745127002172\n",
      "Indexis: [4, 5, 13, 10] Test index: 9 Acc: 0.05107252767655712\n",
      "Indexis: [4, 5, 13, 10] Test index: 11 Acc: 0.0510628592581035\n",
      "Indexis: [4, 5, 13, 10] Test index: 12 Acc: 0.04984181305517721\n",
      "Indexis: [4, 5, 13, 10, 7] Test index: 0 Acc: 0.053017825354255144\n",
      "Indexis: [4, 5, 13, 10, 7] Test index: 1 Acc: 0.051891222172276597\n",
      "Indexis: [4, 5, 13, 10, 7] Test index: 2 Acc: 0.05328578439563591\n",
      "Indexis: [4, 5, 13, 10, 7] Test index: 3 Acc: 0.05217026319064899\n",
      "Indexis: [4, 5, 13, 10, 7] Test index: 6 Acc: 0.052075743941826784\n",
      "Indexis: [4, 5, 13, 10, 7] Test index: 8 Acc: 0.05328740923504549\n",
      "Indexis: [4, 5, 13, 10, 7] Test index: 9 Acc: 0.051510538157178765\n",
      "Indexis: [4, 5, 13, 10, 7] Test index: 11 Acc: 0.05257611233813975\n",
      "Indexis: [4, 5, 13, 10, 7] Test index: 12 Acc: 0.050893486096606044\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, random_state=1)\n",
    "\n",
    "indexis = []\n",
    "accuracies = []\n",
    "index = -1\n",
    "max_accuracy = 0\n",
    "improved = False\n",
    "\n",
    "for iter in range(len(X_train[0]) - 1):\n",
    "    improved = False\n",
    "    if iter != 0:\n",
    "        X_train_subset = X_train[:,indexis[0]]\n",
    "        X_test_subset = X_test[:,indexis[0]]\n",
    "        X_train_subset = X_train_subset.reshape(-1, 1)\n",
    "        X_test_subset = X_test_subset.reshape(-1, 1)\n",
    "        for j in range(1, len(indexis)):\n",
    "            X_train_subset = np.concatenate((X_train_subset, X_train[:, indexis[j]].reshape(-1, 1)), axis=1)\n",
    "            X_test_subset = np.concatenate((X_test_subset, X_test[:, indexis[j]].reshape(-1, 1)), axis=1)\n",
    "    for i in range(len(X_train[0])):\n",
    "        if not i in indexis:\n",
    "            if iter == 0:\n",
    "                X_train_sub = X_train[:,i]\n",
    "                X_test_sub = X_test[:,i]\n",
    "                X_train_sub = X_train_sub.reshape(-1, 1)\n",
    "                X_test_sub = X_test_sub.reshape(-1, 1)\n",
    "            else:\n",
    "                X_train_sub = np.concatenate((X_train_subset, X_train[:,i].reshape(-1, 1)), axis=1)\n",
    "                X_test_sub =  np.concatenate(( X_test_subset,  X_test[:,i].reshape(-1, 1)), axis=1)\n",
    "\n",
    "            regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train_sub, y_train)\n",
    "            accuracy = regr.score(X_test_sub, y_test)\n",
    "            print(\"Indexis: \" + str(indexis) + \" Test index: \" + str(i) + \" Acc: \" + str(accuracy))\n",
    "            if accuracy > max_accuracy:\n",
    "                improved = True\n",
    "                max_accuracy = accuracy\n",
    "                index = i\n",
    "    if not improved:\n",
    "        break\n",
    "    indexis.append(index)\n",
    "    accuracies.append(max_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.05121036936778278\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels,\n",
    "                                                    random_state=1)\n",
    "regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Splitting values at 0.0\nSplitting values at 1.0\nSplitting values at 24.0\nSplitting values at 34.0\nSplitting values at 40.0\nSplitting values at 45.0\nSplitting values at 52.0\nSplitting values at 59.0\nSplitting values at 66.0\n5274\n1759\n0.11119010379638845\n"
     ]
    }
   ],
   "source": [
    "new_labels_yo = extr.catagorize(labels, .10)\n",
    "new_labels_yo = extr.catagorize(labels, .20)\n",
    "new_labels_yo = extr.catagorize(labels, .30)\n",
    "new_labels_yo = extr.catagorize(labels, .40)\n",
    "new_labels_yo = extr.catagorize(labels, .50)\n",
    "new_labels_yo = extr.catagorize(labels, .60)\n",
    "new_labels_yo = extr.catagorize(labels, .70)\n",
    "new_labels_yo = extr.catagorize(labels, .80)\n",
    "new_labels_yo = extr.catagorize(labels, .90)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, new_labels_yo)\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "ones = 0\n",
    "otherones = 0\n",
    "for i in range(len(labels)):\n",
    "    #print(labels[i], \" : \", new_labels_yo[i])\n",
    "    if new_labels_yo[i] == 1:\n",
    "        ones += 1\n",
    "\n",
    "print(ones / len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Splitting values at 52.0\n",
      "Splitting values at 52.0\n",
      "Splitting values at 52.0\n",
      "Splitting values at 52.0\n",
      "Splitting values at 52.0\n",
      "0.7125639567936327\n",
      "[0.7125639567936327]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "popularity_perc = [.7]\n",
    "averages = []\n",
    "averaging = 5\n",
    "for per in popularity_perc:\n",
    "    average = 0\n",
    "    for i in range(averaging):\n",
    "        new_labels = extr.catagorize(labels, per)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, new_labels, stratify=new_labels)\n",
    "        clf = MLPClassifier(nesterovs_momentum=True, max_iter=500).fit(X_train, y_train)\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        average += accuracy\n",
    "    average = average / averaging\n",
    "    averages.append(average)\n",
    "    print(average)\n",
    "print(averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "popularity_perc = [.7]\n",
    "averages = []\n",
    "averaging = 5\n",
    "for per in popularity_perc:\n",
    "    average = 0\n",
    "    for i in range(averaging):\n",
    "        new_labels = extr.catagorize(labels, per)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, new_labels, stratify=new_labels)\n",
    "        clf = MLPClassifier(nesterovs_momentum=True, max_iter=500).fit(X_train, y_train)\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        average += accuracy\n",
    "    average = average / averaging\n",
    "    averages.append(average)\n",
    "    print(average)\n",
    "print(averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dimensions\n",
      "7033\n",
      "5\n",
      "Percentage Popular: 0.7\n",
      "Splitting values at 24.0\n",
      "0.7055144968732234\n",
      "Percentage Popular: 0.6\n",
      "Splitting values at 34.0\n",
      "0.6054576463899943\n",
      "Percentage Popular: 0.5\n",
      "Splitting values at 40.0\n",
      "0.564525298465037\n",
      "Percentage Popular: 0.4\n",
      "Splitting values at 45.0\n",
      "0.625923820352473\n",
      "Percentage Popular: 0.30000000000000004\n",
      "Splitting values at 52.0\n",
      "0.7032404775440592\n",
      "Percentage Popular: 0.19999999999999996\n",
      "Splitting values at 59.0\n",
      "0.8021603183627061\n",
      "Percentage Popular: 0.09999999999999998\n",
      "Splitting values at 66.0\n",
      "0.8885730528709495\n"
     ]
    }
   ],
   "source": [
    "#Basic classifier\n",
    "\n",
    "import dataextractor as de\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "extr = de.DataExtractor()\n",
    "data = extr.load_json().to_array()\n",
    "\n",
    "labels = data[:,-1]\n",
    "data = data[:,:-1]\n",
    "data = extr.normalize(data)\n",
    "\n",
    "\n",
    "indexis_fs = [4, 5, 13, 10, 7]\n",
    "indexis_fr = [1, 4, 5, 8, 9]\n",
    "\n",
    "X_train_subset = data[:,indexis_fs[0]]\n",
    "X_train_subset = X_train_subset.reshape(-1, 1)\n",
    "for j in range(1, len(indexis_fs)):\n",
    "    X_train_subset = np.concatenate((X_train_subset, data[:, indexis_fs[j]].reshape(-1, 1)), axis=1)\n",
    "\n",
    "percentages = [.3, .4, .5, .6, .7, .8, .9]\n",
    "# Change this: .7 means 70% are not popular\n",
    "print(\"dimensions\")\n",
    "print(len(X_train_subset))\n",
    "print(len(X_train_subset[0]))\n",
    "\n",
    "for per in percentages:\n",
    "    print(\"Percentage Popular: \" + str(1 - per))\n",
    "    new_labels = extr.catagorize(labels, per)\n",
    "    X_train_subset = data[:,indexis_fs[0]]\n",
    "    X_train_subset = X_train_subset.reshape(-1, 1)\n",
    "    for j in range(1, len(indexis_fs)):\n",
    "        X_train_subset = np.concatenate((X_train_subset, data[:, indexis_fs[j]].reshape(-1, 1)), axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_subset, new_labels, stratify=new_labels)\n",
    "    clf = MLPClassifier(nesterovs_momentum=True, max_iter=500).fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dimensions\n",
      "7033\n",
      "5\n",
      "Percentage Popular: 0.7\n",
      "Splitting values at 24.0\n",
      "0.7055144968732234\n",
      "Percentage Popular: 0.6\n",
      "Splitting values at 34.0\n",
      "0.6048891415577032\n",
      "Percentage Popular: 0.5\n",
      "Splitting values at 40.0\n",
      "0.5588402501421262\n",
      "Percentage Popular: 0.4\n",
      "Splitting values at 45.0\n",
      "0.6077316657191586\n",
      "Percentage Popular: 0.30000000000000004\n",
      "Splitting values at 52.0\n",
      "0.7072200113700966\n",
      "Percentage Popular: 0.19999999999999996\n",
      "Splitting values at 59.0\n",
      "0.8032973280272883\n",
      "Percentage Popular: 0.09999999999999998\n",
      "Splitting values at 66.0\n",
      "0.8885730528709495\n"
     ]
    }
   ],
   "source": [
    "#Basic classifier\n",
    "\n",
    "import dataextractor as de\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "extr = de.DataExtractor()\n",
    "data = extr.load_json().to_array()\n",
    "\n",
    "labels = data[:,-1]\n",
    "data = data[:,:-1]\n",
    "data = extr.normalize(data)\n",
    "\n",
    "\n",
    "indexis_fs = [4, 5, 13, 10, 7]\n",
    "indexis_fr = [1, 4, 5, 8, 9]\n",
    "\n",
    "X_train_subset = data[:,indexis_fr[0]]\n",
    "X_train_subset = X_train_subset.reshape(-1, 1)\n",
    "for j in range(1, len(indexis_fs)):\n",
    "    X_train_subset = np.concatenate((X_train_subset, data[:, indexis_fr[j]].reshape(-1, 1)), axis=1)\n",
    "\n",
    "percentages = [.3, .4, .5, .6, .7, .8, .9]\n",
    "# Change this: .7 means 70% are not popular\n",
    "print(\"dimensions\")\n",
    "print(len(X_train_subset))\n",
    "print(len(X_train_subset[0]))\n",
    "\n",
    "for per in percentages:\n",
    "    print(\"Percentage Popular: \" + str(1 - per))\n",
    "    new_labels = extr.catagorize(labels, per)\n",
    "    X_train_subset = data[:,indexis_fs[0]]\n",
    "    X_train_subset = X_train_subset.reshape(-1, 1)\n",
    "    for j in range(1, len(indexis_fs)):\n",
    "        X_train_subset = np.concatenate((X_train_subset, data[:, indexis_fs[j]].reshape(-1, 1)), axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_subset, new_labels, stratify=new_labels)\n",
    "    clf = MLPClassifier(nesterovs_momentum=True, max_iter=500).fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dimensions\n",
      "7033\n",
      "5\n",
      "Percentage Popular: 0.30000000000000004\n",
      "Splitting values at 52.0\n",
      "0.709494030699261\n",
      "In: [0.00000000e+00 1.00606673e-05 5.35822402e-01 5.93582888e-02\n",
      " 9.46410516e-02]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.00000000e+00 1.00606673e-05 5.35822402e-01 5.93582888e-02\n 9.46410516e-02].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-91012a9118e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"In: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"True out: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Predicted: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/cs472/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \"\"\"\n\u001b[1;32m    952\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coefs_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cs472/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \"\"\"\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;31m# Make sure self.hidden_layer_sizes is a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cs472/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    550\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.00000000e+00 1.00606673e-05 5.35822402e-01 5.93582888e-02\n 9.46410516e-02].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "#Basic classifier\n",
    "\n",
    "import dataextractor as de\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "extr = de.DataExtractor()\n",
    "data = extr.load_json().to_array()\n",
    "\n",
    "labels = data[:,-1]\n",
    "data = data[:,:-1]\n",
    "data = extr.normalize(data)\n",
    "\n",
    "\n",
    "indexis_fs = [4, 5, 13, 10, 7]\n",
    "indexis_fr = [1, 4, 5, 8, 9]\n",
    "\n",
    "X_train_subset = data[:,indexis_fr[0]]\n",
    "X_train_subset = X_train_subset.reshape(-1, 1)\n",
    "for j in range(1, len(indexis_fs)):\n",
    "    X_train_subset = np.concatenate((X_train_subset, data[:, indexis_fr[j]].reshape(-1, 1)), axis=1)\n",
    "\n",
    "percentages = [.7]\n",
    "# Change this: .7 means 70% are not popular\n",
    "print(\"dimensions\")\n",
    "print(len(X_train_subset))\n",
    "print(len(X_train_subset[0]))\n",
    "\n",
    "for per in percentages:\n",
    "    print(\"Percentage Popular: \" + str(1 - per))\n",
    "    new_labels = extr.catagorize(labels, per)\n",
    "    X_train_subset = data[:,indexis_fs[0]]\n",
    "    X_train_subset = X_train_subset.reshape(-1, 1)\n",
    "    for j in range(1, len(indexis_fs)):\n",
    "        X_train_subset = np.concatenate((X_train_subset, data[:, indexis_fs[j]].reshape(-1, 1)), axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_subset, new_labels, stratify=new_labels)\n",
    "    clf = MLPClassifier(nesterovs_momentum=True, max_iter=500).fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    print(accuracy)\n",
    "\n",
    "predicted_stuff = clf.predict(X_test[i])\n",
    "\n",
    "for i in range(20):\n",
    "    print(\"In: \" + str(X_test[i]))\n",
    "    print(\"True out: \" + str(y_test[i]) + \" Predicted: \" + str(predicted_stuff[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}